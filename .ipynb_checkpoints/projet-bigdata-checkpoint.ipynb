{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "130d5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession,DataFrame\n",
    "from typing import Optional\n",
    "import logging\n",
    "\n",
    "class SparkClass:\n",
    "    def __init__(self):\n",
    "        logging.info(\"Initialisation de spark !\")\n",
    "    \n",
    "    def createSession(self,master:Optional['str']=\"local[*]\", app_name:Optional['str']=\"BigData Machine Learning\") -> SparkSession:\n",
    "        spark = SparkSession.builder.master(master).appName(app_name).getOrCreate()\n",
    "        print(\"Démarrage de la session\")\n",
    "        return spark\n",
    "    \n",
    "    def destroySession(self,spark:SparkSession):\n",
    "        spark.stop() if isinstance(spark, SparkSession) else None\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff277dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.ml.feature import StringIndexer,VectorAssembler \n",
    "import pathlib, os, logging\n",
    "\n",
    "\n",
    "\n",
    "class DataPreprocessing:\n",
    "    \n",
    "    def __init__(self):\n",
    "        logging.info(\"Pré-traitement des données !\")\n",
    "    \n",
    "    def createDataFrame(self,spark:SparkSession,filePath:str) -> DataFrame:\n",
    "        if os.path.exists(filePath) and os.path.isfile(filePath) :\n",
    "            extension = pathlib.Path(filePath).suffix\n",
    "        else: raise Exception('Erreur, essayer encore')\n",
    "        \n",
    "        def fromCSV(filePath:str) -> DataFrame:\n",
    "            df = spark.read.options(header='True', inferSchema='True', delimiter=',') \\\n",
    "                .csv(filePath)\n",
    "            return df\n",
    "        \n",
    "        def fromJSON(filePath:str) -> DataFrame:\n",
    "            df = spark.read.json(filePath)\n",
    "            return df\n",
    "        return fromCSV(filePath) if extension==\".csv\" else fromJSON(filePath) \n",
    "    \n",
    "    def transformToNumeric(self,df:DataFrame, input:str, output:str) -> DataFrame:\n",
    "        indexer = StringIndexer(inputCol=input, outputCol=output)\n",
    "        df_transformed = indexer.fit(df).transform(df)\n",
    "        df_transformed = df_transformed.drop(input)\n",
    "        return df_transformed\n",
    "    \n",
    "    def indexerColumns(self,colums:List['str']) -> List[StringIndexer]:\n",
    "        columnsIndexed = []\n",
    "        for column in colums:\n",
    "            col=\"\"\n",
    "            if column==\"Classes\":\n",
    "                col=\"label\"\n",
    "            else:\n",
    "                col = column+\"_indexed\"\n",
    "            st = StringIndexer(inputCol=column,outputCol=col)\n",
    "            st.setHandleInvalid(\"skip\")\n",
    "            columnsIndexed.append(st)\n",
    "        return columnsIndexed\n",
    "    \n",
    "    def groupeColumns(self,df:DataFrame,vectorAssembler:VectorAssembler) -> DataFrame:\n",
    "        assembled_df = vectorAssembler.transform(df)\n",
    "        return assembled_df\n",
    "    \n",
    "    def renameCol(self,df:DataFrame,exist:str,newCol:str) -> DataFrame:\n",
    "        n_df = df.withColumnRenamed(exist,newCol )\n",
    "        return n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c25cbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer \n",
    "from pyspark.ml.classification import NaiveBayes \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml import Transformer\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "class ModelNaiveBayes:\n",
    "    def __init__(self):\n",
    "        logging.info(\"Apprentissage avec mon modéle\")\n",
    "        \n",
    "        \n",
    "    def train(self,df:DataFrame,nbModel:NaiveBayes) -> Transformer:\n",
    "        model = nbModel.fit(df)\n",
    "        return model\n",
    "    \n",
    "    def predict(self,df:DataFrame, tf:Transformer) -> DataFrame:\n",
    "        predicted_df = tf.transform(df)\n",
    "        return predicted_df\n",
    "    \n",
    "    def evaluateModel(self,df:DataFrame, evaluator:MulticlassClassificationEvaluator) -> float:\n",
    "         accuracy = evaluator.evaluate(df)\n",
    "         return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35029735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de la session\n",
      "<pyspark.sql.session.SparkSession object at 0x000002B9388A3780>\n",
      "Session démarrée\n",
      "Transformation des données catégorielles en données numériques\n",
      "+-----------+-----------+-------------+------------+-------------------+----------+----------+------------+------------+-----------+----------+-----------+-----------+-----------+-----+\n",
      "|    Classes|day_indexed|month_indexed|year_indexed|Temperature_indexed|RH_indexed|Ws_indexed|Rain_indexed|FFMC_indexed|DMC_indexed|DC_indexed|ISI_indexed|BUI_indexed|FWI_indexed|label|\n",
      "+-----------+-----------+-------------+------------+-------------------+----------+----------+------------+------------+-----------+----------+-----------+-----------+-----------+-----+\n",
      "|not fire   |        0.0|          2.0|         0.0|                7.0|      37.0|       5.0|         0.0|        89.0|       10.0|       2.0|       14.0|       37.0|        4.0|  1.0|\n",
      "|not fire   |        1.0|          2.0|         0.0|                7.0|      39.0|       2.0|        14.0|        84.0|       44.0|       2.0|        3.0|        9.0|        0.0|  1.0|\n",
      "|not fire   |        2.0|          2.0|         0.0|               13.0|      41.0|      12.0|        23.0|        62.0|        6.0|     160.0|       24.0|       28.0|        3.0|  1.0|\n",
      "|not fire   |        3.0|          2.0|         0.0|               11.0|      44.0|       2.0|        26.0|        50.0|        3.0|     151.0|        9.0|       15.0|        2.0|  1.0|\n",
      "|not fire   |        4.0|          2.0|         0.0|               10.0|      40.0|       4.0|         0.0|        87.0|        8.0|      47.0|        1.0|        9.0|        4.0|  1.0|\n",
      "|    fire   |        5.0|          2.0|         0.0|                1.0|      28.0|       0.0|         0.0|       134.0|       13.0|      82.0|       28.0|      163.0|       12.0|  0.0|\n",
      "|    fire   |        6.0|          2.0|         0.0|                3.0|       2.0|       2.0|         0.0|       157.0|       55.0|      15.0|       93.0|        2.0|       45.0|  0.0|\n",
      "|    fire   |        7.0|          2.0|         0.0|                4.0|       8.0|       1.0|         0.0|        34.0|       25.0|     118.0|        8.0|       72.0|       44.0|  0.0|\n",
      "|not fire   |        8.0|          2.0|         0.0|               11.0|      43.0|       2.0|         2.0|        68.0|        0.0|     119.0|        2.0|       17.0|        5.0|  1.0|\n",
      "|not fire   |        9.0|          2.0|         0.0|                8.0|      30.0|       9.0|         0.0|       106.0|      164.0|      21.0|       14.0|       68.0|        6.0|  1.0|\n",
      "|    fire   |       10.0|          2.0|         0.0|                1.0|       5.0|       0.0|         0.0|        25.0|        2.0|     143.0|       31.0|       21.0|       40.0|  0.0|\n",
      "|    fire   |       11.0|          2.0|         0.0|               13.0|      14.0|       6.0|         0.0|       140.0|       28.0|     153.0|       23.0|       24.0|       44.0|  0.0|\n",
      "|not fire   |       12.0|          2.0|         0.0|               10.0|      50.0|       7.0|         9.0|        66.0|      155.0|       7.0|       38.0|       47.0|        7.0|  1.0|\n",
      "|not fire   |       13.0|          2.0|         0.0|                4.0|       4.0|      11.0|         7.0|        74.0|       12.0|       3.0|        3.0|       10.0|        0.0|  1.0|\n",
      "|not fire   |       14.0|          2.0|         0.0|                8.0|       9.0|       3.0|        17.0|        65.0|        8.0|      24.0|        2.0|        0.0|        3.0|  1.0|\n",
      "+-----------+-----------+-------------+------------+-------------------+----------+----------+------------+------------+-----------+----------+-----------+-----------+-----------+-----+\n",
      "only showing top 15 rows\n",
      "\n",
      "+--------------------------------------------------------------+-----+\n",
      "|features                                                      |label|\n",
      "+--------------------------------------------------------------+-----+\n",
      "|[0.0,2.0,0.0,7.0,37.0,5.0,0.0,89.0,10.0,2.0,14.0,37.0,4.0]    |1.0  |\n",
      "|[1.0,2.0,0.0,7.0,39.0,2.0,14.0,84.0,44.0,2.0,3.0,9.0,0.0]     |1.0  |\n",
      "|[2.0,2.0,0.0,13.0,41.0,12.0,23.0,62.0,6.0,160.0,24.0,28.0,3.0]|1.0  |\n",
      "|[3.0,2.0,0.0,11.0,44.0,2.0,26.0,50.0,3.0,151.0,9.0,15.0,2.0]  |1.0  |\n",
      "|[4.0,2.0,0.0,10.0,40.0,4.0,0.0,87.0,8.0,47.0,1.0,9.0,4.0]     |1.0  |\n",
      "|[5.0,2.0,0.0,1.0,28.0,0.0,0.0,134.0,13.0,82.0,28.0,163.0,12.0]|0.0  |\n",
      "|[6.0,2.0,0.0,3.0,2.0,2.0,0.0,157.0,55.0,15.0,93.0,2.0,45.0]   |0.0  |\n",
      "|[7.0,2.0,0.0,4.0,8.0,1.0,0.0,34.0,25.0,118.0,8.0,72.0,44.0]   |0.0  |\n",
      "|[8.0,2.0,0.0,11.0,43.0,2.0,2.0,68.0,0.0,119.0,2.0,17.0,5.0]   |1.0  |\n",
      "|[9.0,2.0,0.0,8.0,30.0,9.0,0.0,106.0,164.0,21.0,14.0,68.0,6.0] |1.0  |\n",
      "+--------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[0.0,0.0,0.0,7.0,...|  1.0|[-40.590637771008...|[0.00112615360532...|       1.0|\n",
      "|[0.0,1.0,0.0,15.0...|  1.0|[-36.947599490163...|[0.02694847191923...|       1.0|\n",
      "|[0.0,3.0,0.0,7.0,...|  1.0|[-35.969069808781...|[0.00238354105055...|       1.0|\n",
      "|[1.0,0.0,0.0,10.0...|  1.0|[-36.045696643730...|[0.00942371083745...|       1.0|\n",
      "|[2.0,0.0,0.0,2.0,...|  0.0|[-30.667815808101...|[0.65797393266832...|       0.0|\n",
      "|[2.0,1.0,0.0,0.0,...|  1.0|[-34.582227015530...|[0.08210449553339...|       1.0|\n",
      "|[2.0,3.0,0.0,8.0,...|  0.0|[-33.392925601196...|[0.04631705466438...|       1.0|\n",
      "|[3.0,2.0,0.0,11.0...|  1.0|[-53.528389314679...|[9.85363811268985...|       4.0|\n",
      "|[4.0,3.0,0.0,7.0,...|  0.0|[-33.468086907923...|[0.01905820174567...|       1.0|\n",
      "|[5.0,1.0,0.0,4.0,...|  1.0|[-39.934963532902...|[1.89345271482425...|       1.0|\n",
      "|[5.0,2.0,0.0,0.0,...|  0.0|[-35.125155419764...|[0.70798816105482...|       0.0|\n",
      "|[5.0,2.0,0.0,1.0,...|  0.0|[-32.603732206289...|[0.48692239983252...|       1.0|\n",
      "|[6.0,0.0,0.0,0.0,...|  1.0|[-32.243237072481...|[0.39936219195199...|       1.0|\n",
      "|[7.0,0.0,0.0,3.0,...|  0.0|[-31.349157632719...|[0.99999999999034...|       0.0|\n",
      "|[7.0,1.0,0.0,9.0,...|  0.0|[-32.463939415404...|[0.02059834933017...|       1.0|\n",
      "|[10.0,0.0,0.0,3.0...|  1.0|[-29.511006445433...|[0.98498227259210...|       0.0|\n",
      "|[10.0,3.0,0.0,4.0...|  1.0|[-32.717265584464...|[0.16369123961812...|       1.0|\n",
      "|[11.0,2.0,0.0,13....|  0.0|[-32.353696908220...|[0.59980200601843...|       0.0|\n",
      "|[12.0,2.0,0.0,4.0...|  1.0|[-34.652208495791...|[9.05364144847374...|       1.0|\n",
      "|[13.0,0.0,0.0,2.0...|  1.0|[-32.797693193793...|[0.28450624340022...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Accuracy =  0.76\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer,VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "import os\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "classSpark = SparkClass()\n",
    "session = classSpark.createSession()\n",
    "print(session)\n",
    "print(\"Session démarrée\")\n",
    "\"\"\"\n",
    "Chargement des données\n",
    "\"\"\"\n",
    "# os.path.abspath(__file__)\n",
    "fileCSV = \"Algerian_forest_fires_dataset_UPDATE.csv\"\n",
    "fileJSON = \"people.json\"\n",
    "dataPrep = DataPreprocessing()\n",
    "df_l = dataPrep.createDataFrame(session,fileCSV)\n",
    "\"\"\"\n",
    "    Transformation des données catégorielles en données numériques\n",
    "\"\"\"\n",
    "print(\"Transformation des données catégorielles en données numériques\")\n",
    "indexers = dataPrep.indexerColumns(df_l.columns)\n",
    "pipeline = Pipeline(stages=indexers) \n",
    "indexed_df = pipeline.fit(df_l).transform(df_l)\n",
    "\n",
    "indexed_df = indexed_df.drop(\"day\",\"month\",\"year\",\"Temperature\",\"RH\",\"Ws\",\"Rain\",\"FFMC\",\"DMC\",\"DC\",\"ISI\",\"BUI\",\"FWI\")\n",
    "indexed_df.show(15)\n",
    "\n",
    "cols = [\"day_indexed\",\"month_indexed\",\"year_indexed\",\"Temperature_indexed\",\"RH_indexed\",\"Ws_indexed\",\"Rain_indexed\",\"FFMC_indexed\",\"DMC_indexed\",\"DC_indexed\",\"ISI_indexed\",\"BUI_indexed\",\"FWI_indexed\"]\n",
    "vec = VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "df_ass = dataPrep.groupeColumns(indexed_df,vec)\n",
    "df_ass.select(\"features\",\"label\").show(10,False)\n",
    "\"\"\"\n",
    " Entrainement du modéle\n",
    "\"\"\"\n",
    "train, test= df_ass.select(\"features\",\"label\").randomSplit([0.8, 0.2])\n",
    "\n",
    "nb = NaiveBayes(modelType=\"gaussian\")\n",
    "nb_model = ModelNaiveBayes()\n",
    "transformer = nb_model.train(train,nb)\n",
    "\n",
    "prediction_df = nb_model.predict(test,transformer)\n",
    "\n",
    "prediction_df.show(20)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy =  nb_model.evaluateModel(prediction_df,evaluator)\n",
    "print(\"Accuracy = \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ace915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyton-env",
   "language": "python",
   "name": "pyton-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
